{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759513905065,
     "user": {
      "displayName": "Michael Mathias",
      "userId": "03670979792358760203"
     },
     "user_tz": -60
    },
    "id": "DjxoKJfdGItJ"
   },
   "outputs": [],
   "source": [
    "## IMDB - Top 250 TV Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413545,
     "status": "ok",
     "timestamp": 1759514518790,
     "user": {
      "displayName": "Michael Mathias",
      "userId": "03670979792358760203"
     },
     "user_tz": -60
    },
    "id": "hFk9qGYLP2Q7",
    "outputId": "37b5cdb9-fed6-48a7-9903-4504f76474d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape Completed!\n"
     ]
    }
   ],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "import re\n",
    "import random\n",
    "\n",
    "async def imdb_tv():\n",
    "    url = \"https://m.imdb.com/chart/toptv/\"\n",
    "    results = []\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True, args=[\"--no-sandbox\"])\n",
    "        context = await browser.new_context(user_agent=(\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/128.0.0.0 Safari/537.36\"\n",
    "            ))\n",
    "        page = await context.new_page()\n",
    "\n",
    "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
    "\n",
    "        # Get links\n",
    "        links = await page.eval_on_selector_all(\n",
    "            \"a[href*='/title/tt']\",\n",
    "            \"els => els.map(el => el.href)\"\n",
    "            )\n",
    "\n",
    "        # Extract just the main ID part to normalize\n",
    "        normalized_links = []\n",
    "\n",
    "        for link in links:\n",
    "            match = re.search(r'(https://m\\.imdb\\.com/title/tt\\d+)', link)\n",
    "\n",
    "            if match:\n",
    "                normalized_links.append(match.group(1))\n",
    "\n",
    "                # Remove duplicates after normalization\n",
    "                links = list(dict.fromkeys(normalized_links))\n",
    "\n",
    "        for idx, link in enumerate(links[:60], start=1):\n",
    "            try:\n",
    "                await page.goto(link, timeout=60000)\n",
    "            except:\n",
    "                print(f\"Failed to load page {link}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                title = await page.inner_text(\"h1[data-testid='hero__pageTitle'] span.hero__primary-text\")\n",
    "            except:\n",
    "                title = None\n",
    "\n",
    "\n",
    "            try:\n",
    "                rating = await page.inner_text(\"div[data-testid='hero-rating-bar__aggregate-rating__score'] span\")\n",
    "            except:\n",
    "                rating = None\n",
    "\n",
    "            try:\n",
    "                creator = await page.eval_on_selector(\n",
    "                    \"a.ipc-metadata-list-item__list-content-item--link\",\n",
    "                    \"el => el.innerText\"\n",
    "                    )\n",
    "            except:\n",
    "                creator = None\n",
    "\n",
    "            try:\n",
    "                reviews = await page.inner_text(\"a.isReview span.score\")\n",
    "            except:\n",
    "                reviews = None\n",
    "\n",
    "            results.append({\n",
    "                \"Rank\": idx,\n",
    "                \"Title\": title,\n",
    "                \"Rating\": rating,\n",
    "                \"Creator\": creator,\n",
    "                \"Reviews\": reviews\n",
    "                })\n",
    "\n",
    "            await asyncio.sleep(random.uniform(0.3, 0.8))\n",
    "\n",
    "        await browser.close()\n",
    "    return results\n",
    "\n",
    "data = await imdb_tv()\n",
    "print(\"Scrape Completed!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1759514748574,
     "user": {
      "displayName": "Michael Mathias",
      "userId": "03670979792358760203"
     },
     "user_tz": -60
    },
    "id": "MHrMFNxQWCwu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"IMDb Top Tv Shows\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgopshc+M5XGi9FN1sp/GB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
