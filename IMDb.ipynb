{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsC8jFT9C7UtR2Fv6j2ZHf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjxoKJfdGItJ"
      },
      "outputs": [],
      "source": [
        "## IMDB - Top 250 TV Series"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "import re\n",
        "import random\n",
        "\n",
        "async def imdb_tv():\n",
        "    url = \"https://m.imdb.com/chart/toptv/\"\n",
        "    results = []\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True, args=[\"--no-sandbox\"])\n",
        "        context = await browser.new_context(user_agent=(\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/128.0.0.0 Safari/537.36\"\n",
        "            ))\n",
        "        page = await context.new_page()\n",
        "\n",
        "        await page.goto(url, wait_until=\"domcontentloaded\")\n",
        "\n",
        "        # Get links\n",
        "        links = await page.eval_on_selector_all(\n",
        "            \"a[href*='/title/tt']\",\n",
        "            \"els => els.map(el => el.href)\"\n",
        "            )\n",
        "\n",
        "        # Extract just the main ID part to normalize\n",
        "        normalized_links = []\n",
        "\n",
        "        for link in links:\n",
        "            match = re.search(r'(https://m\\.imdb\\.com/title/tt\\d+)', link)\n",
        "\n",
        "            if match:\n",
        "                normalized_links.append(match.group(1))\n",
        "\n",
        "                # Remove duplicates after normalization\n",
        "                links = list(dict.fromkeys(normalized_links))\n",
        "\n",
        "        for idx, link in enumerate(links[:60], start=1):\n",
        "            try:\n",
        "                await page.goto(link, timeout=60000)\n",
        "            except:\n",
        "                print(f\"Failed to load page {link}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                title = await page.inner_text(\"h1[data-testid='hero__pageTitle'] span.hero__primary-text\")\n",
        "            except:\n",
        "                title = None\n",
        "\n",
        "\n",
        "            try:\n",
        "                rating = await page.inner_text(\"div[data-testid='hero-rating-bar__aggregate-rating__score'] span\")\n",
        "            except:\n",
        "                rating = None\n",
        "\n",
        "            try:\n",
        "                creator = await page.eval_on_selector(\n",
        "                    \"a.ipc-metadata-list-item__list-content-item--link\",\n",
        "                    \"el => el.innerText\"\n",
        "                    )\n",
        "            except:\n",
        "                creator = None\n",
        "\n",
        "            try:\n",
        "                reviews = await page.inner_text(\"a.isReview span.score\")\n",
        "            except:\n",
        "                reviews = None\n",
        "\n",
        "            results.append({\n",
        "                \"Rank\": idx,\n",
        "                \"Title\": title,\n",
        "                \"Rating\": rating,\n",
        "                \"Creator\": creator,\n",
        "                \"Reviews\": reviews\n",
        "                })\n",
        "\n",
        "            await asyncio.sleep(random.uniform(0.3, 0.8))\n",
        "\n",
        "        await browser.close()\n",
        "    return results\n",
        "\n",
        "data = await imdb_tv()\n",
        "print(\"Scrape Completed!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hFk9qGYLP2Q7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e24fad-bb40-44dc-be16-ab240e480a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scrape Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "MHrMFNxQWCwu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}